{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6Ga8eXaqFxm"
      },
      "source": [
        "**Before running this notebook, please add a shortcut of the RecSys folder to the root directory of your drive (MyDrive)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ7z6B42a9Mo",
        "outputId": "14b26d2e-d4da-421f-b17e-038a213074d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYCdTXr6oRbJ"
      },
      "source": [
        "The following is for the KAN layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCsxdjNDzbsm",
        "outputId": "47756c0f-99a6-4aee-d4d5-f99dc9e33c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'fast-kan' already exists and is not an empty directory.\n",
            "Processing ./fast-kan\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fastkan==0.0.1) (1.26.4)\n",
            "Building wheels for collected packages: fastkan\n",
            "  Building wheel for fastkan (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastkan: filename=fastkan-0.0.1-py3-none-any.whl size=11560 sha256=054fcc422dae8151f15b0aae0a3b059a13931b69382aec3106b34fc9d9e5bb8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/67/af/0e9541499b9ccc4465dae8c80e40769cc637277b82bcfeb08b\n",
            "Successfully built fastkan\n",
            "Installing collected packages: fastkan\n",
            "  Attempting uninstall: fastkan\n",
            "    Found existing installation: fastkan 0.0.1\n",
            "    Uninstalling fastkan-0.0.1:\n",
            "      Successfully uninstalled fastkan-0.0.1\n",
            "Successfully installed fastkan-0.0.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ZiyaoLi/fast-kan\n",
        "\n",
        "!pip install '/content/fast-kan/.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Br9CQ3F3ajGr"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/RecSys/')\n",
        "sys.path.append('/content/drive/MyDrive/RecSys/model/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VkelKA4CZRZz"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random as rnd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Subset,random_split,default_collate\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nf267ZqmZRZz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from numba import jit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eomVLTrYZRZ0"
      },
      "outputs": [],
      "source": [
        "from Recommender import AEReco\n",
        "from MovieLens_4Colab import Movie_1M, CombinedDataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mszCIm8oBz3"
      },
      "source": [
        "I already have the pre-processed data saved, so there is no need to unquote the following blocks until we get a new dataset or run cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jxQyGUuwZRZ1"
      },
      "outputs": [],
      "source": [
        "dataset = Movie_1M()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.users.values[2]"
      ],
      "metadata": {
        "id": "YUgctluGiwR6",
        "outputId": "8b67acac-4d21-42db-b83d-17b5b11cf088",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, list([0, 0, 1, 0, 0, 0, 0]), 0,\n",
              "       list([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
              "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "id": "H7XR334kFQ1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5afa6fcf-6f02-46d6-88cc-5439cb2d5dad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000209"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.random.permutation(len(dataset))\n",
        "train_index = indices[:int(round(0.9*len(dataset)))] #change the train_test_split to 9:1"
      ],
      "metadata": {
        "id": "fdJ9mBKc9cmF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.users"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "XB-OWAtMwYUx",
        "outputId": "a0afafca-e65c-44bf-cd0d-955ac4288adf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      user_id                    age  gender  \\\n",
              "0           1  [1, 0, 0, 0, 0, 0, 0]       1   \n",
              "1           2  [0, 0, 0, 0, 0, 0, 1]       0   \n",
              "2           3  [0, 0, 1, 0, 0, 0, 0]       0   \n",
              "3           4  [0, 0, 0, 0, 1, 0, 0]       0   \n",
              "4           5  [0, 0, 1, 0, 0, 0, 0]       0   \n",
              "...       ...                    ...     ...   \n",
              "6035     6036  [0, 0, 1, 0, 0, 0, 0]       1   \n",
              "6036     6037  [0, 0, 0, 0, 1, 0, 0]       1   \n",
              "6037     6038  [0, 0, 0, 0, 0, 0, 1]       1   \n",
              "6038     6039  [0, 0, 0, 0, 1, 0, 0]       1   \n",
              "6039     6040  [0, 0, 1, 0, 0, 0, 0]       0   \n",
              "\n",
              "                               zip_code  \\\n",
              "0     [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]   \n",
              "1     [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]   \n",
              "2     [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]   \n",
              "3     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "4     [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]   \n",
              "...                                 ...   \n",
              "6035  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]   \n",
              "6036  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]   \n",
              "6037  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "6038  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "6039  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "\n",
              "                                             occupation  \n",
              "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
              "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
              "3     [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "...                                                 ...  \n",
              "6035  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
              "6036  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "6037  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "6038  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "6039  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "\n",
              "[6040 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04483080-f957-4986-aa63-de7a24c35450\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>zip_code</th>\n",
              "      <th>occupation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6035</th>\n",
              "      <td>6036</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6036</th>\n",
              "      <td>6037</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6037</th>\n",
              "      <td>6038</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6038</th>\n",
              "      <td>6039</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039</th>\n",
              "      <td>6040</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6040 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04483080-f957-4986-aa63-de7a24c35450')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04483080-f957-4986-aa63-de7a24c35450 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04483080-f957-4986-aa63-de7a24c35450');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-efacc136-5129-43ae-bc64-0a39b59ca70b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-efacc136-5129-43ae-bc64-0a39b59ca70b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-efacc136-5129-43ae-bc64-0a39b59ca70b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 6040,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1743,\n        \"min\": 1,\n        \"max\": 6040,\n        \"num_unique_values\": 6040,\n        \"samples\": [\n          5530,\n          711,\n          4924\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"zip_code\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occupation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_rating, train_mask, test_rating, test_mask, user_matrix, item_matrix = dataset.preprocessor(train_index, fourier = False)"
      ],
      "metadata": {
        "id": "yO0Nt3cJ9Uzh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34RoDIzVoPrC"
      },
      "source": [
        "Loading the Model ... the configuration file should be pretty straightforward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc-I1b91XxQG"
      },
      "source": [
        "The configuration file: MovieLens1M.yaml\n",
        "\n",
        "> Add blockquote\n",
        "\n",
        "\n",
        "\n",
        "For fine-tuning: please change parameters from the yaml so that we don't have to restart the run time every time a hyper-parameter is changed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y6o4RHmM8OLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2358a60a-5905-4366-f58e-d8f47c213902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " \t ----------- Model = Recommender with Autoencoder ------------\n",
            "\n",
            " \t \t Autoencoder = DAE_KAN \n",
            "\n",
            " \t ----------- Model Loaded ------------\n",
            "\t *Total Params* =  36440528\n",
            "\t *Trainable Params* =  36440512\n"
          ]
        }
      ],
      "source": [
        "model = AEReco(configuration_file = '/content/drive/MyDrive/RecSys/MovieLens1M.yaml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SBACarmoWKP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y089h_8AocWF"
      },
      "source": [
        "The following blocks are all for data pre-processing. Change the random seed to change the train/test sets for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xFbUVg-AoC3c"
      },
      "outputs": [],
      "source": [
        "#train_test_ratio = 0.8\n",
        "#np.random.seed(42)\n",
        "#indices = np.random.permutation(100000)\n",
        "#train_index = indices[:int(train_test_ratio*100000)]\n",
        "#test_index = indices[int(train_test_ratio*100000):]\n",
        "#train_dataset = Subset(dataset, train_index)\n",
        "#test_dataset = Subset(dataset, test_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "S5UjRFpi7que"
      },
      "outputs": [],
      "source": [
        "#rating, user, item, mask = model.preprocessor(train_dataset, dataset)\n",
        "#test_rating, _, _, test_mask = model.preprocessor(test_dataset, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VFerrgDqE0Na"
      },
      "outputs": [],
      "source": [
        "#torch.save(train_mask, '/content/drive/MyDrive/RecSys/1m_mask_nf.pt')\n",
        "#torch.save(train_rating, '/content/drive/MyDrive/RecSys/1m_rating_nf.pt')\n",
        "#torch.save(user_matrix, '/content/drive/MyDrive/RecSys/1m_user_nf.pt')\n",
        "#torch.save(item_matrix, '/content/drive/MyDrive/RecSys/1m_item_nf.pt')\n",
        "#torch.save(test_rating, '/content/drive/MyDrive/RecSys/1m_test_rating_nf.pt')\n",
        "#torch.save(test_mask, '/content/drive/MyDrive/RecSys/1m_test_mask_nf.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YyEkW_rokte"
      },
      "source": [
        "Loading the saved training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xj62SfllFI3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b743e3-c117-4ba3-8cfc-d9141702fa2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-516b6fedb41c>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train_mask = torch.load('/content/drive/MyDrive/RecSys/1m_mask_nf.pt')\n",
            "<ipython-input-17-516b6fedb41c>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train_rating = torch.load('/content/drive/MyDrive/RecSys/1m_rating_nf.pt')\n",
            "<ipython-input-17-516b6fedb41c>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  user_matrix = torch.load('/content/drive/MyDrive/RecSys/1m_user_nf.pt')\n",
            "<ipython-input-17-516b6fedb41c>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  item_matrix = torch.load('/content/drive/MyDrive/RecSys/1m_item_nf.pt')\n",
            "<ipython-input-17-516b6fedb41c>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test_rating = torch.load('/content/drive/MyDrive/RecSys/1m_test_rating_nf.pt')\n",
            "<ipython-input-17-516b6fedb41c>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test_mask = torch.load('/content/drive/MyDrive/RecSys/1m_test_mask_nf.pt')\n"
          ]
        }
      ],
      "source": [
        "train_mask = torch.load('/content/drive/MyDrive/RecSys/1m_mask_nf.pt')\n",
        "train_rating = torch.load('/content/drive/MyDrive/RecSys/1m_rating_nf.pt')\n",
        "user_matrix = torch.load('/content/drive/MyDrive/RecSys/1m_user_nf.pt')\n",
        "item_matrix = torch.load('/content/drive/MyDrive/RecSys/1m_item_nf.pt')\n",
        "test_rating = torch.load('/content/drive/MyDrive/RecSys/1m_test_rating_nf.pt')\n",
        "test_mask = torch.load('/content/drive/MyDrive/RecSys/1m_test_mask_nf.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kS0HHPGBW1g"
      },
      "source": [
        "\n",
        "\n",
        "The following train-test split is when we attempt to see how the algorithm deal with the cold start issue. *PLEASE DONT DELETE ANY OF THE CODES*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "poft_rQcZRZ1"
      },
      "outputs": [],
      "source": [
        "#train_test_ratio = 0.8\n",
        "#indices = np.random.permutation(user.shape[0])\n",
        "#train_index = indices[:int(train_test_ratio*user.shape[0])]\n",
        "#test_index = indices[int(train_test_ratio*user.shape[0]):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Eo5rc6UFAawP"
      },
      "outputs": [],
      "source": [
        "train_rating = torch.tensor(train_rating)\n",
        "user_matrix = torch.tensor(user_matrix)\n",
        "item_matrix = torch.tensor(item_matrix)\n",
        "item_matrix = torch.nan_to_num(item_matrix, nan=0)\n",
        "train_mask = torch.tensor(train_mask)\n",
        "test_rating = torch.tensor(test_rating)\n",
        "test_mask = torch.tensor(test_mask)\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vzs7nTXfA2nn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94b1fdad-218e-4b40-9c99-2637b5f669c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item: torch.Size([3952, 19])\n",
            "user: torch.Size([6040, 39])\n"
          ]
        }
      ],
      "source": [
        "print(f'item: {item_matrix.shape}')\n",
        "print(f'user: {user_matrix.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXeyOvFnsnbI"
      },
      "source": [
        "**Re-run the following codes for Cross-Validation after running new dataset construction codes at the bottom.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SpOvSbnhymqj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def custom_collate(batch, batch_size, dataset):\n",
        "    if len(batch) < batch_size:\n",
        "\n",
        "        additional_samples_needed = batch_size - len(batch)\n",
        "        indices = np.random.choice(len(dataset), additional_samples_needed)\n",
        "        additional_data = [dataset[idx] for idx in indices]\n",
        "        batch.extend(additional_data)\n",
        "    return default_collate(batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kjrHOUkmzQhL"
      },
      "outputs": [],
      "source": [
        "batch_size = model.batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6_DSQbYAl22F"
      },
      "outputs": [],
      "source": [
        "combineset = CombinedDataset(user_matrix, train_rating, train_mask)\n",
        "combine_testset = CombinedDataset(user_matrix, test_rating, test_mask)\n",
        "dataset = DataLoader(combineset, batch_size = batch_size, shuffle = True,\n",
        "                     collate_fn=lambda x: custom_collate(x, batch_size, combineset))\n",
        "test_dataset = DataLoader(combine_testset, batch_size = batch_size, shuffle = False,\n",
        "                     collate_fn=lambda x: custom_collate(x, batch_size, combineset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agI6mFnVvR-g"
      },
      "source": [
        "### Remember to set a unique run_id to make fine-tuning easer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reload the drive to update config\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6HXW2Si9m6h",
        "outputId": "5c62db80-80d3-42f8-a35b-a289c3cc6d8d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1ZoHKvTxt8b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac3f2d2-76c1-4688-c1e7-b0a5732d6847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " \t ----------- Model = Recommender with Autoencoder ------------\n",
            "\n",
            " \t \t Autoencoder = DAE_KAN \n",
            "\n",
            " \t ----------- Model Loaded ------------\n",
            "\t *Total Params* =  36440528\n",
            "\t *Trainable Params* =  36440512\n"
          ]
        }
      ],
      "source": [
        "model = AEReco(configuration_file = '/content/drive/MyDrive/RecSys/MovieLens1M.yaml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FLzinWKtZRZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17cd2df3-894f-4e01-ca7e-c4642041c853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 12/12 [00:02<00:00,  4.30batch/s, loss=0.335]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 1, Average Training RMSE = 2.2587\n",
            "\t Training time for current epoch: 2.8 seconds\n",
            "\t RMSE on testing set : 1.8667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 12/12 [00:02<00:00,  5.37batch/s, loss=0.196]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 2, Average Training RMSE = 1.7426\n",
            "\t Training time for current epoch: 2.24 seconds\n",
            "\t RMSE on testing set : 1.3817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 12/12 [00:02<00:00,  4.18batch/s, loss=0.131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 3, Average Training RMSE = 1.3576\n",
            "\t Training time for current epoch: 2.88 seconds\n",
            "\t RMSE on testing set : 1.1502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 12/12 [00:02<00:00,  4.78batch/s, loss=0.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 4, Average Training RMSE = 1.1974\n",
            "\t Training time for current epoch: 2.52 seconds\n",
            "\t RMSE on testing set : 1.132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 12/12 [00:02<00:00,  5.40batch/s, loss=0.104]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 5, Average Training RMSE = 1.1358\n",
            "\t Training time for current epoch: 2.23 seconds\n",
            "\t RMSE on testing set : 1.038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 12/12 [00:02<00:00,  5.13batch/s, loss=0.0975]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 6, Average Training RMSE = 1.0799\n",
            "\t Training time for current epoch: 2.35 seconds\n",
            "\t RMSE on testing set : 1.0376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 12/12 [00:02<00:00,  5.64batch/s, loss=0.0941]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 7, Average Training RMSE = 1.0651\n",
            "\t Training time for current epoch: 2.13 seconds\n",
            "\t RMSE on testing set : 1.0605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 12/12 [00:02<00:00,  4.74batch/s, loss=0.0865]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 8, Average Training RMSE = 1.0682\n",
            "\t Training time for current epoch: 2.54 seconds\n",
            "\t RMSE on testing set : 1.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 12/12 [00:02<00:00,  4.52batch/s, loss=0.0847]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 9, Average Training RMSE = 1.0198\n",
            "\t Training time for current epoch: 2.66 seconds\n",
            "\t RMSE on testing set : 0.9891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 12/12 [00:02<00:00,  5.44batch/s, loss=0.0806]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 10, Average Training RMSE = 1.0065\n",
            "\t Training time for current epoch: 2.21 seconds\n",
            "\t RMSE on testing set : 0.9706\n",
            "checkpoint saved at epoch 10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 12/12 [00:02<00:00,  5.14batch/s, loss=0.0875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 11, Average Training RMSE = 1.0037\n",
            "\t Training time for current epoch: 2.34 seconds\n",
            "\t RMSE on testing set : 0.9982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 12/12 [00:02<00:00,  4.86batch/s, loss=0.0821]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 12, Average Training RMSE = 1.0035\n",
            "\t Training time for current epoch: 2.48 seconds\n",
            "\t RMSE on testing set : 0.9762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 12/12 [00:02<00:00,  4.70batch/s, loss=0.0843]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 13, Average Training RMSE = 0.9989\n",
            "\t Training time for current epoch: 2.56 seconds\n",
            "\t RMSE on testing set : 0.9891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 12/12 [00:03<00:00,  3.70batch/s, loss=0.0822]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 14, Average Training RMSE = 0.9978\n",
            "\t Training time for current epoch: 3.25 seconds\n",
            "\t RMSE on testing set : 0.9756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 12/12 [00:02<00:00,  4.79batch/s, loss=0.0839]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 15, Average Training RMSE = 0.9976\n",
            "\t Training time for current epoch: 2.51 seconds\n",
            "\t RMSE on testing set : 0.9838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 12/12 [00:02<00:00,  5.36batch/s, loss=0.0823]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 16, Average Training RMSE = 0.997\n",
            "\t Training time for current epoch: 2.25 seconds\n",
            "\t RMSE on testing set : 0.972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 12/12 [00:02<00:00,  4.50batch/s, loss=0.0818]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 17, Average Training RMSE = 0.9964\n",
            "\t Training time for current epoch: 2.68 seconds\n",
            "\t RMSE on testing set : 0.9763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 12/12 [00:02<00:00,  5.29batch/s, loss=0.0864]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 18, Average Training RMSE = 0.9991\n",
            "\t Training time for current epoch: 2.27 seconds\n",
            "\t RMSE on testing set : 0.9961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 12/12 [00:02<00:00,  5.49batch/s, loss=0.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 19, Average Training RMSE = 0.9967\n",
            "\t Training time for current epoch: 2.19 seconds\n",
            "\t RMSE on testing set : 0.9623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 12/12 [00:02<00:00,  5.64batch/s, loss=0.0841]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 20, Average Training RMSE = 0.996\n",
            "\t Training time for current epoch: 2.14 seconds\n",
            "\t RMSE on testing set : 0.9901\n",
            "checkpoint saved at epoch 20.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 12/12 [00:02<00:00,  4.52batch/s, loss=0.0849]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 21, Average Training RMSE = 0.9964\n",
            "\t Training time for current epoch: 2.66 seconds\n",
            "\t RMSE on testing set : 0.995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 12/12 [00:02<00:00,  4.98batch/s, loss=0.0833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 22, Average Training RMSE = 0.9972\n",
            "\t Training time for current epoch: 2.42 seconds\n",
            "\t RMSE on testing set : 0.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 12/12 [00:02<00:00,  5.03batch/s, loss=0.0856]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 23, Average Training RMSE = 0.9968\n",
            "\t Training time for current epoch: 2.39 seconds\n",
            "\t RMSE on testing set : 0.9936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 12/12 [00:04<00:00,  2.86batch/s, loss=0.0837]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 24, Average Training RMSE = 0.9947\n",
            "\t Training time for current epoch: 4.21 seconds\n",
            "\t RMSE on testing set : 0.9853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 12/12 [00:02<00:00,  4.47batch/s, loss=0.0823]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 25, Average Training RMSE = 0.9978\n",
            "\t Training time for current epoch: 2.69 seconds\n",
            "\t RMSE on testing set : 0.9694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 12/12 [00:02<00:00,  5.00batch/s, loss=0.0799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 26, Average Training RMSE = 0.9954\n",
            "\t Training time for current epoch: 2.41 seconds\n",
            "\t RMSE on testing set : 0.9535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 12/12 [00:02<00:00,  5.40batch/s, loss=0.0833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 27, Average Training RMSE = 0.9951\n",
            "\t Training time for current epoch: 2.23 seconds\n",
            "\t RMSE on testing set : 0.9789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 12/12 [00:02<00:00,  5.34batch/s, loss=0.0832]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 28, Average Training RMSE = 0.9945\n",
            "\t Training time for current epoch: 2.25 seconds\n",
            "\t RMSE on testing set : 0.9816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 12/12 [00:02<00:00,  5.41batch/s, loss=0.0824]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 29, Average Training RMSE = 0.995\n",
            "\t Training time for current epoch: 2.22 seconds\n",
            "\t RMSE on testing set : 0.9826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 12/12 [00:02<00:00,  4.49batch/s, loss=0.0874]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 30, Average Training RMSE = 0.9976\n",
            "\t Training time for current epoch: 2.68 seconds\n",
            "\t RMSE on testing set : 1.005\n",
            "checkpoint saved at epoch 30.\n"
          ]
        }
      ],
      "source": [
        "model.train(dataset, item_matrix, test_dataset, epoch =30)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}