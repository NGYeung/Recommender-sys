{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "cJ7z6B42a9Mo",
        "outputId": "7bc6a8a1-6fce-4f9d-ace9-dfcd14fca13d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/RecSys/')\n",
        "sys.path.append('/content/drive/MyDrive/RecSys/model/')"
      ],
      "metadata": {
        "id": "Br9CQ3F3ajGr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VkelKA4CZRZz"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random as rnd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Subset,random_split,default_collate\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nf267ZqmZRZz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from numba import jit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eomVLTrYZRZ0"
      },
      "outputs": [],
      "source": [
        "from Recommender import AEReco\n",
        "from MovieLens_4Colab import Movie_100K, CombinedDataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jxQyGUuwZRZ1"
      },
      "outputs": [],
      "source": [
        "dataset = Movie_100K()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAoFSPhJ9Pen",
        "outputId": "acca5962-72e9-4a06-e197-8106e2aa0693"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'user_id': 1,\n",
              " 'age': 0.8,\n",
              " 'gender': 0,\n",
              " 'zip_code': array([ 0.00000000e+00,  5.00000000e-01,  8.66025404e-01,  1.00000000e+00,\n",
              "         8.66025404e-01,  5.00000000e-01,  1.22464680e-16, -5.00000000e-01,\n",
              "        -8.66025404e-01, -1.00000000e+00, -8.66025404e-01, -5.00000000e-01]),\n",
              " 'occupation': array([ 0.        ,  0.27783279,  0.10412135, -0.238812  , -0.19361916,\n",
              "         0.16625078,  0.25592374, -0.07034012, -0.28228459, -0.03544959,\n",
              "         0.2689994 ,  0.13626052, -0.21793406, -0.21793406,  0.13626052,\n",
              "         0.2689994 , -0.03544959, -0.28228459, -0.07034012,  0.25592374,\n",
              "         0.16625078, -0.19361916, -0.238812  ,  0.10412135,  0.27783279]),\n",
              " 'rating': 4,\n",
              " 'timestamp': 878542420,\n",
              " 'movie_id': 61,\n",
              " 'date': array([1.2       , 0.5       , 0.8660254 , 0.5       , 0.97952994]),\n",
              " 'genre': array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AEReco()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6o4RHmM8OLH",
        "outputId": "b775dd28-d11c-41d1-fc10-008db16e8db2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " \t ----------- Model = Recommender with Autoencoder ------------\n",
            "\n",
            " \t \t Autoencoder = DAE \n",
            "\n",
            " \t ----------- Model Loaded ------------\n",
            "\t *Total Params* =  445235464\n",
            "\t *Trainable Params* =  445235464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_ratio = 0.8\n",
        "np.random.seed(42)\n",
        "indices = np.random.permutation(100000)\n",
        "train_index = indices[:int(train_test_ratio*100000)]\n",
        "test_index = indices[int(train_test_ratio*100000):]\n",
        "train_dataset = Subset(dataset, train_index)\n",
        "test_dataset = Subset(dataset, test_index)\n"
      ],
      "metadata": {
        "id": "xFbUVg-AoC3c"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rating, user, item, mask = model.preprocessor(train_dataset, dataset)"
      ],
      "metadata": {
        "id": "S5UjRFpi7que"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OpiKM7sVpulR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(mask, '/content/drive/MyDrive/RecSys/mask.pt')\n",
        "#torch.save(rating, '/content/drive/MyDrive/RecSys/rating.pt')\n",
        "#torch.save(user, '/content/drive/MyDrive/RecSys/user.pt')\n",
        "#torch.save(item, '/content/drive/MyDrive/RecSys/item.pt')"
      ],
      "metadata": {
        "id": "VFerrgDqE0Na"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating = torch.load('/content/drive/MyDrive/RecSys/rating.pt')\n",
        "user = torch.load('/content/drive/MyDrive/RecSys/user.pt')\n",
        "item = torch.load('/content/drive/MyDrive/RecSys/item.pt')\n",
        "mask = torch.load('/content/drive/MyDrive/RecSys/mask.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj62SfllFI3l",
        "outputId": "dc7853b2-391b-455b-a33a-f25bb8c3ddbc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-b930700b3dfa>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  rating = torch.load('/content/drive/MyDrive/RecSys/rating.pt')\n",
            "<ipython-input-12-b930700b3dfa>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  user = torch.load('/content/drive/MyDrive/RecSys/user.pt')\n",
            "<ipython-input-12-b930700b3dfa>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  item = torch.load('/content/drive/MyDrive/RecSys/item.pt')\n",
            "<ipython-input-12-b930700b3dfa>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  mask = torch.load('/content/drive/MyDrive/RecSys/mask.pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following way is when we attempt to see how the algorithm deal with the slow start issue."
      ],
      "metadata": {
        "id": "1kS0HHPGBW1g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "poft_rQcZRZ1"
      },
      "outputs": [],
      "source": [
        "#train_test_ratio = 0.8\n",
        "#indices = np.random.permutation(user.shape[0])\n",
        "#train_index = indices[:int(train_test_ratio*user.shape[0])]\n",
        "#test_index = indices[int(train_test_ratio*user.shape[0]):]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rating_train = rating[train_index]\n",
        "#mask_train = mask[train_index]\n",
        "#user_train = user[train_index]\n",
        "\n",
        "#rating_test = rating[test_index]\n",
        "#mask_test = mask[test_index]\n",
        "#user_test = user[test_index]"
      ],
      "metadata": {
        "id": "Eo5rc6UFAawP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'item: {item.shape}')\n",
        "print(f'user: {user.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzs7nTXfA2nn",
        "outputId": "1b65314f-0956-4056-b1e2-3b6dc1abd08f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item: torch.Size([1682, 26])\n",
            "user: (943, 59)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def custom_collate(batch, batch_size, dataset):\n",
        "    if len(batch) < batch_size:\n",
        "\n",
        "        additional_samples_needed = batch_size - len(batch)\n",
        "        indices = np.random.choice(len(dataset), additional_samples_needed)\n",
        "        additional_data = [dataset[idx] for idx in indices]\n",
        "        batch.extend(additional_data)\n",
        "    return default_collate(batch)\n",
        ""
      ],
      "metadata": {
        "id": "SpOvSbnhymqj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combineset = CombinedDataset(user, rating, mask)\n",
        "dataset = DataLoader(combineset, batch_size = 64, shuffle = True,\n",
        "                     collate_fn=lambda x: custom_collate(x, 64, combineset))"
      ],
      "metadata": {
        "id": "6_DSQbYAl22F"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZC9HZGgYpbDf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLzinWKtZRZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eff94e8-0c6d-4585-fafc-862324a7659d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 15/15 [00:03<00:00,  3.96batch/s, loss=0.107]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 1, RMSE = 1.9803\n",
            "\t Training time for current epoch: 3.79 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 15/15 [00:03<00:00,  4.45batch/s, loss=0.114]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 2, RMSE = 1.9261\n",
            "\t Training time for current epoch: 3.38 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 15/15 [00:03<00:00,  4.29batch/s, loss=0.122]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 3, RMSE = 1.8914\n",
            "\t Training time for current epoch: 3.5 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 15/15 [00:03<00:00,  4.50batch/s, loss=0.0917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 4, RMSE = 1.8281\n",
            "\t Training time for current epoch: 3.34 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 15/15 [00:03<00:00,  4.50batch/s, loss=0.101]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 5, RMSE = 1.7851\n",
            "\t Training time for current epoch: 3.34 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 15/15 [00:03<00:00,  4.50batch/s, loss=0.0864]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 6, RMSE = 1.745\n",
            "\t Training time for current epoch: 3.34 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 15/15 [00:03<00:00,  4.30batch/s, loss=0.0968]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 7, RMSE = 1.7213\n",
            "\t Training time for current epoch: 3.5 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 15/15 [00:03<00:00,  4.47batch/s, loss=0.088]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 8, RMSE = 1.7011\n",
            "\t Training time for current epoch: 3.36 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 15/15 [00:03<00:00,  4.48batch/s, loss=0.112]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 9, RMSE = 1.6862\n",
            "\t Training time for current epoch: 3.36 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10:  93%|█████████▎| 14/15 [00:03<00:00,  4.46batch/s, loss=0.121]"
          ]
        }
      ],
      "source": [
        "model.train(dataset, item, epoch = 90)\n",
        "# with hidden_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_checkpoint(10)"
      ],
      "metadata": {
        "id": "Z3Tt3L_dNcVN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}